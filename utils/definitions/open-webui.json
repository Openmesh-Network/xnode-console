{
  "name": "Open WebUI",
  "desc": "Deploy Open WebUI with a single click to unlock an advanced, self-hosted interface for interacting with AI models. It supports seamless multi-modal interaction and can operate entirely offline, ensuring maximum privacy for your data.",
  "longDesc": "**What is Open WebUI?**\n\nOpen WebUI is an extensible platform designed for users to run AI models and facilitate complex interactions locally. It offers comprehensive support for various LLMs, including compatibility with Ollama and OpenAI APIs, along with the ability to host RAG (Retrieval Augmented Generation) workflows, chat interfaces, and more.\n\n**Key Features:**\n\n- **One-Click Deployment:** Simplified through Docker containers, eliminating configuration complexities.\n- **Multi-Model Support:** Manage and switch between multiple AI models such as Ollama or OpenAI-based LLMs.\n- **Modular Functionality:** Utilize tools for document processing, embedding models, and model fine-tuning within a unified workspace.\n- **Privacy and Security:** Keeps all data local, avoiding external servers to maintain user control over sensitive information.\n- **Versatile Interactions:** Supports chat, code completion, document search, and even summarization of YouTube videos through RAG pipelines.",
  "useCases": "- **Developers:** Run code assistants locally to boost productivity with enhanced privacy.\n- **Enterprises:** Create internal chatbots or other automation tools to streamline workflows while keeping data confidential.\n- **Educators & Researchers:** Use AI models for teaching or experimentation without reliance on internet connectivity.",
  "support": "- **Community Channels:** Join the [Open WebUI Discord](https://discord.com) for real-time help and discussions.\n- **Documentation:** Explore setup guides and troubleshooting steps in the [Open WebUI documentation](https://docs.openwebui.com).\n- **Additional Help:** Access regular updates and in-depth tutorials on [Open WebUI's GitHub](https://github.com/open-webui/open-webui).",
  "nixName": "open-webui",
  "specs": {
    "ram": 400,
    "storage": 100
  },
  "tags": ["LLM"],
  "website": "https://github.com/open-webui/open-webui",
  "implemented": true,
  "logo": "",
  "options": [
    {
      "name": "enable",
      "desc": "Whether to enable Open-WebUI server.",
      "nixName": "enable",
      "type": "boolean",
      "value": "true"
    },
    {
      "name": "environment",
      "desc": "Extra environment variables for Open-WebUI",
      "nixName": "environment",
      "type": "attribute set of string",
      "value": "{\n  ANONYMIZED_TELEMETRY = \"False\";\n  DO_NOT_TRACK = \"True\";\n  SCARF_NO_ANALYTICS = \"True\";\n}"
    },
    {
      "name": "host",
      "desc": "The host address which the Open-WebUI server HTTP interface listens to.",
      "nixName": "host",
      "type": "string",
      "value": "0.0.0.0"
    },
    {
      "name": "openFirewall",
      "desc": "Whether to open the firewall for Open-WebUI. This adds services.open-webui.port to networking.firewall.allowedTCPPorts.",
      "nixName": "openFirewall",
      "type": "boolean",
      "value": "true"
    },
    {
      "name": "port",
      "desc": "Which port the Open-WebUI server listens to.",
      "nixName": "port",
      "type": "16 bit unsigned integer; between 0 and 65535 (both inclusive)",
      "value": "8080"
    },
    {
      "name": "stateDir",
      "desc": "State directory of Open-WebUI.",
      "nixName": "stateDir",
      "type": "path",
      "value": "\"/var/lib/open-webui\""
    }
  ]
}
